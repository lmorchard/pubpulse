{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25c4307a-bdb5-4a29-9527-4625fd7ad19a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# PubPulse laboratory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2b9217-9bee-4422-a7c7-b4dfd6318db9",
   "metadata": {},
   "source": [
    "Import and set up some handy things..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42337d8a-d711-4dd5-9b33-e8e6689c6b3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext sql\n",
    "    \n",
    "import os, sys\n",
    "\n",
    "# todo: figure out if / how to preload notebook with python path access to mastodon_agent in parent directory\n",
    "sys.path.insert(0, os.path.dirname(os.getcwd()))\n",
    "\n",
    "import torch\n",
    "import math\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "from pgvector.psycopg2 import register_vector\n",
    "from tqdm.notebook import trange, tqdm\n",
    "from IPython.display import HTML\n",
    "from ipywidgets import IntProgress\n",
    "from IPython.display import display\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.orm import Session\n",
    "\n",
    "from mastodon_agent.config import config\n",
    "from mastodon_agent.tasks import ml_gpu\n",
    "\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "os.environ['DATABASE_URL'] = config.database_url\n",
    "engine = create_engine(config.database_url)\n",
    "\n",
    "# this ensures that the current MacOS version is at least 12.3+\n",
    "print(torch.backends.mps.is_available())\n",
    "# this ensures that the current current PyTorch installation was built with MPS activated.\n",
    "print(torch.backends.mps.is_built())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9d50c8-9fab-4e5b-b502-ae41454957c0",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "How many statuses have we ingested so far?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ea169b9-4bbf-478f-a55f-ca083d685470",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>count</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>199264</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "[(199264,)]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%sql SELECT count(*) FROM statuses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5130e998-f2d5-44e1-a9ab-6e54b1043602",
   "metadata": {},
   "source": [
    "Let's take a look at the latest posts ingested:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b279b93-6db0-4de0-baae-79330be6f70e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://postgres:***@localhost:55432/example\n"
     ]
    }
   ],
   "source": [
    "%%sql\n",
    "SELECT\n",
    "    url,\n",
    "    ingested_at,\n",
    "    status->>'created_at' as created_at,\n",
    "    status->'account'->>'acct' as acct\n",
    "FROM statuses\n",
    "ORDER BY ingested_at DESC\n",
    "LIMIT 5;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0bbf539-0897-411c-97de-451d8a9e90eb",
   "metadata": {},
   "source": [
    "Try fetching the latest posts using python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f433121f-50c2-4b8b-81b7-4c1463919b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy.sql import text\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    stmt = text(\"\"\"\n",
    "        SELECT\n",
    "            ingested_at,\n",
    "            status->>'created_at' as created_at,\n",
    "            url,\n",
    "            status->'account'->>'acct' as acct,\n",
    "            status->>'content' as content\n",
    "        FROM statuses\n",
    "        ORDER BY ingested_at DESC\n",
    "        LIMIT 3;\n",
    "    \"\"\")\n",
    "    result = conn.execute(stmt)\n",
    "    \n",
    "from collections import namedtuple\n",
    "\n",
    "Record = namedtuple('Record', result.keys())\n",
    "records = [Record(*r) for r in result.fetchall()]\n",
    "\n",
    "texts = [r.content for r in records if r.content]\n",
    "\n",
    "df = pd.DataFrame(records)\n",
    "HTML(df.to_html(render_links=True, escape=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e5eb3a-71fc-4107-a42c-1505c624ceac",
   "metadata": {},
   "source": [
    "Let's load up a local embedding model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a657a35a-b86a-4013-8021-b939279d5e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "embedding_model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e3bea8-3c15-43a4-b988-1e76fc3876f4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Try comparing a few different ways to access an embedding model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73474ba3-e700-44c2-8d7a-510f92ca1cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "from mastodon_agent.tasks import ml_gpu\n",
    "\n",
    "texts = [\n",
    "    \"I like pie\",\n",
    "    \"Have you the like of pie!\",\n",
    "    \"Lorem ipsum dolor sit amet consectetur adipiscing elit Aliquam mattis arcu sit amet ex convallis ac varius lacus vehicula\",\n",
    "    \"Etiam non feugiat sapien. Vestibulum accumsan elit massa, at volutpat augue lacinia lacinia.\",\n",
    "]\n",
    "\n",
    "local_api_resp = requests.post(\n",
    "    f\"{config.ml_api_url}/embeddings\",\n",
    "    json = { \"inputs\": texts }\n",
    ")\n",
    "embeddings_from_local_api = local_api_resp.json()\n",
    "\n",
    "response = requests.post(\n",
    "    f\"https://api-inference.huggingface.co/pipeline/feature-extraction/sentence-transformers/all-MiniLM-L6-v2\",\n",
    "    headers={\"Authorization\": f\"Bearer {config.hf_token}\"},\n",
    "    json={\n",
    "        \"inputs\": texts,\n",
    "        \"options\":{\"wait_for_model\":True}\n",
    "    }\n",
    ")\n",
    "embeddings_from_hf = response.json()\n",
    "\n",
    "embeddings_from_model = embedding_model.encode(texts)\n",
    "\n",
    "embeddings_from_celery = ml_gpu.embed.delay(texts).get(timeout=10)\n",
    "\n",
    "pd.DataFrame([\n",
    "    embeddings_from_local_api[0],\n",
    "    embeddings_from_hf[0],\n",
    "    embeddings_from_model[0],\n",
    "    embeddings_from_celery[0],\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7425a580-5b5e-4761-a683-acb45045fbab",
   "metadata": {},
   "source": [
    "How many ingested statuses do we have since the last newest generated embedding?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0affd45c-6c8b-422f-af85-2c4d7459865a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT count(url)\n",
    "FROM statuses\n",
    "WHERE ingested_at > (SELECT created_at FROM status_embeddings ORDER BY created_at DESC LIMIT 1);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7feba4d7-d58c-410f-a92e-eff7a3e857ac",
   "metadata": {},
   "source": [
    "Generate embeddings for statuses newer than the newest embedding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc86a82a-250e-4efe-9063-50d9c85b6682",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mastodon_agent.tasks import ml_gpu\n",
    "\n",
    "conn = psycopg2.connect(os.environ[\"DATABASE_URL\"])\n",
    "register_vector(conn)\n",
    "\n",
    "cur = conn.cursor()\n",
    "cur.execute(\"\"\"\n",
    "    SELECT\n",
    "        url,\n",
    "        status->>'content' as content\n",
    "    FROM statuses    \n",
    "    WHERE ingested_at > (\n",
    "        SELECT created_at\n",
    "        FROM status_embeddings\n",
    "        ORDER BY created_at DESC\n",
    "        LIMIT 1\n",
    "    )\n",
    "    ORDER BY ingested_at DESC\n",
    "    LIMIT 5000\n",
    "\"\"\")\n",
    "\n",
    "def embed_with_local_api(texts):\n",
    "    response = requests.post(\n",
    "        f\"{config.ml_api_url}/embeddings\",\n",
    "        json = { \"inputs\": texts }\n",
    "    )\n",
    "    return response.json()\n",
    "\n",
    "def embed_with_hf_api(texts):\n",
    "    response = requests.post(\n",
    "        f\"https://api-inference.huggingface.co/pipeline/feature-extraction/sentence-transformers/all-MiniLM-L6-v2\",\n",
    "        headers={\"Authorization\": f\"Bearer {config.hf_token}\"},\n",
    "        json={\n",
    "            \"inputs\": texts,\n",
    "            \"options\":{\"wait_for_model\":True}\n",
    "        }\n",
    "    )\n",
    "    return response.json()\n",
    "    \n",
    "def embed_with_inprocess_model(texts):\n",
    "    return embedding_model.encode(texts)\n",
    "\n",
    "def embed_with_celery_job(texts):\n",
    "    return ml_gpu.embed.delay(texts).get(timeout=10)\n",
    "\n",
    "embed = embed_with_celery_job\n",
    "\n",
    "CHUNK_SIZE = 100\n",
    "chunks = []\n",
    "\n",
    "def embed_statuses_chunk():\n",
    "    global chunks\n",
    "    urls = [c[0] for c in chunks]\n",
    "    texts = [c[1] for c in chunks]\n",
    "    embeddings = embed(texts)\n",
    "\n",
    "    chunks = []\n",
    "\n",
    "    with conn:\n",
    "        with conn.cursor() as cur:\n",
    "            for idx in range(0, len(urls)):\n",
    "                url = urls[idx]\n",
    "                embedding = embeddings[idx]\n",
    "                cur.execute(\n",
    "                    \"\"\"\n",
    "                        INSERT INTO status_embeddings (url, embedding) VALUES (%s, %s)\n",
    "                          ON CONFLICT (url) DO UPDATE SET embedding = EXCLUDED.embedding;            \n",
    "                    \"\"\",\n",
    "                    (url, embedding)\n",
    "                )\n",
    "\n",
    "for row in tqdm(cur, total=cur.rowcount):\n",
    "    chunks.append((row[0], row[1]))\n",
    "    if len(chunks) >= CHUNK_SIZE:    \n",
    "        embed_statuses_chunk()\n",
    "\n",
    "embed_statuses_chunk()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8615a2e-32d3-499a-8bf4-d2a5433a4ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql SELECT count(embedding) FROM status_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809c43b1-a737-4ba4-90b1-f041ffc7dd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#embeddings = embedding_model.encode([\n",
    "#    \"\"\"I really like banana bread\"\"\"\n",
    "#])\n",
    "\n",
    "embeddings = ml_gpu.embed.delay([\n",
    "    \"\"\"retro gaming is nifty\"\"\"\n",
    "]).get(timeout=10)\n",
    "\n",
    "conn = psycopg2.connect(os.environ[\"DATABASE_URL\"])\n",
    "register_vector(conn)\n",
    "\n",
    "cur = conn.cursor()\n",
    "cur.execute(\n",
    "    \"\"\"\n",
    "    SELECT\n",
    "        ingested_at,\n",
    "        url,\n",
    "        status->'account'->>'acct' as acct,\n",
    "        status->>'content' as content\n",
    "    FROM statuses\n",
    "    WHERE url in (\n",
    "        SELECT url\n",
    "        FROM status_embeddings\n",
    "        WHERE created_at > now() - INTERVAL '6 hours'\n",
    "        ORDER BY embedding <-> %s\n",
    "        LIMIT 25\n",
    "    )\n",
    "    ORDER BY ingested_at DESC\n",
    "    LIMIT 25\n",
    "    \"\"\",\n",
    "    (np.array(embeddings[0]),)\n",
    ")\n",
    "rows = cur.fetchall()\n",
    "\n",
    "df = pd.DataFrame(rows, columns=(\"ingested_at\", \"url\", \"acct\", \"content\"))\n",
    "HTML(df.to_html(render_links=True, escape=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
